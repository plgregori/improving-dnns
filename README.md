# Improving Deep Neural Networks

In this repository, we implement and test several tools for making deep neural networks more efficient.

## Initialization

First, we check the performance of three kinds of parameter initialization: zeros, large random numbers, and He initialization.

<p float="left">
<img src="./images/Figure_1.png"  width="32%">
<img src="./images/Figure_2.png"  width="32%">
<img src="./images/Figure_3.png"  width="32%"> 
</p>

## Regularization

Then, on a second dataset, we check the performance of two kinds of regularization: L2 regularization and dropout.

<p float="left">
<img src="./images/Figure_4.png"  width="32%">
<img src="./images/Figure_5.png"  width="32%">
<img src="./images/Figure_6.png"  width="32%"> 
</p>